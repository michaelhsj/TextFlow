{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b394c44d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "from IPython.display import display\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import Tensor\n",
        "import torch\n",
        "from torchvision.io import decode_image\n",
        "from torchvision.transforms.functional import resize\n",
        "import attrs\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "NUM_IMAGES = 100\n",
        "TARGET_IMAGE_SIZE = [1024, 1024]\n",
        "DATASET_DIR = Path(\"../../dataset/TextOCR\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "950e4b83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://huggingface.co/datasets/yunusserhat/TextOCR-Dataset\n",
        "# {\n",
        "#   \"imgs\": {\n",
        "#     \"OpenImages_ImageID_1\": {\n",
        "#       \"id\": \"OpenImages_ImageID_1\",\n",
        "#       \"width\":  W,\n",
        "#       \"height\": H,\n",
        "#       \"set\": \"train|val|test\",\n",
        "#       \"filename\": \"train|test/OpenImages_ImageID_1.jpg\"\n",
        "#     }\n",
        "#   },\n",
        "#   \"anns\": {\n",
        "#     \"OpenImages_ImageID_1_1\": {\n",
        "#       \"id\": \"OpenImages_ImageID_1_1\",\n",
        "#       \"image_id\": \"OpenImages_ImageID_1\",\n",
        "#       \"bbox\": [x1, y1, x2, y2],\n",
        "#       \"points\": [x1, y1, x2, y2, ..., xN, yN],\n",
        "#       \"utf8_string\": \"text\",\n",
        "#       \"area\": A\n",
        "#     }\n",
        "#   },\n",
        "#   \"img2Anns\": {\n",
        "#     \"OpenImages_ImageID_1\": [\"OpenImages_ImageID_1_1\", \"...\"]\n",
        "#   }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ad80cd96",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ml.ingest.textocr_to_torch import TextOCRDoctrDetDataset\n",
        "\n",
        "\n",
        "dataset = TextOCRDoctrDetDataset(num_samples=NUM_IMAGES)\n",
        "loader = DataLoader(dataset, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "63e75640",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_polygons(polys_p_n_2: torch.Tensor) -> list[Tensor]:\n",
        "    \"\"\"\n",
        "    Remove zero-padded points from polygon tensors.\n",
        "    polys_p_n_2: [P, N, 2]\n",
        "    Returns: list of (N_i, 2) numpy arrays (valid polygons)\n",
        "    \"\"\"\n",
        "    cleaned: list[Tensor] = []\n",
        "    for poly in polys_p_n_2:\n",
        "        # keep only points that are not [0,0]\n",
        "        mask = ~torch.all(poly == 0, dim=-1)\n",
        "        valid = poly[mask]\n",
        "        if len(valid) >= 3:  # at least a triangle\n",
        "            cleaned.append(valid)\n",
        "    return cleaned\n",
        "\n",
        "def overlay_polygons(image: torch.Tensor,\n",
        "                     polygons: torch.Tensor,\n",
        "                     alpha: float = 0.5) -> torch.Tensor:\n",
        "\n",
        "    _, H, W = image.shape\n",
        "    unpadded_polys = clean_polygons(polygons)\n",
        "    if not unpadded_polys:\n",
        "        return image\n",
        "\n",
        "    unpadded_polys = [p*TARGET_IMAGE_SIZE[0] for p in unpadded_polys]\n",
        "    \n",
        "    masks = torch.zeros((len(unpadded_polys), H, W), dtype=torch.bool)\n",
        "    for i, poly in enumerate(unpadded_polys):\n",
        "        m = Image.new(mode=\"1\", size=(W, H), color=0)\n",
        "        d = ImageDraw.Draw(m)\n",
        "        d.polygon([p.tolist() for p in poly], fill=1)\n",
        "        masks[i] = torch.from_numpy(np.array(m, dtype=bool))\n",
        "\n",
        "    colors = [\"red\", \"lime\", \"blue\", \"yellow\", \"magenta\", \"cyan\"]\n",
        "    return draw_segmentation_masks(image, masks,\n",
        "                                   colors=[colors[i % len(colors)] for i in range(len(unpadded_polys))],\n",
        "                                   alpha=alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed0441c",
      "metadata": {},
      "outputs": [],
      "source": [
        "images, targets = next(iter(loader))\n",
        "sample_image = images[0]\n",
        "sample_polygons = targets['words'][0]\n",
        "overlay = overlay_polygons(sample_image, sample_polygons, alpha=0.4)\n",
        "display(to_pil_image(overlay))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-textflow (3.11.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
